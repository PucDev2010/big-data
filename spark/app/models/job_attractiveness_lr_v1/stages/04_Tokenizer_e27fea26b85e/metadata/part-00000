{"class":"org.apache.spark.ml.feature.Tokenizer","timestamp":1768831415758,"sparkVersion":"3.5.3","uid":"Tokenizer_e27fea26b85e","paramMap":{"outputCol":"words_raw","inputCol":"full_text_features"},"defaultParamMap":{"outputCol":"Tokenizer_e27fea26b85e__output"}}
