from pyspark.sql import SparkSession
from pyspark.sql.functions import col, when, lower, lit, coalesce
from pyspark.ml.feature import VectorAssembler, StandardScaler
from pyspark.ml.regression import RandomForestRegressor
from pyspark.ml import Pipeline
from pyspark.ml.evaluation import RegressionEvaluator

# ====================================================
# 1. KHá»I Táº O SPARK SESSION
# ====================================================
spark = SparkSession.builder \
    .appName("SalaryPrediction_RandomForest") \
    .config("spark.cassandra.connection.host", "cassandra") \
    .config("spark.cassandra.connection.port", "9042") \
    .getOrCreate()

spark.sparkContext.setLogLevel("WARN")

# ====================================================
# 2. Äá»ŒC Dá»® LIá»†U Tá»ª CASSANDRA
# ====================================================
print(">>> Äang Ä‘á»c dá»¯ liá»‡u tá»« Cassandra...")
df_raw = spark.read \
    .format("org.apache.spark.sql.cassandra") \
    .options(table="job_postings", keyspace="job_analytics") \
    .load()

print(f">>> Tá»•ng sá»‘ jobs: {df_raw.count()}")

# ====================================================
# 3. DATA PREPROCESSING
# ====================================================
print(">>> Äang xá»­ lÃ½ dá»¯ liá»‡u...")

# Lá»c bá» records rÃ¡c
df = df_raw.filter(col("job_title").isNotNull())

# 3.1. Xá»­ lÃ½ LÆ°Æ¡ng (TARGET - Label)
df = df.withColumn(
    "salary_final",
    coalesce(
        col("salary_avg"), 
        (col("salary_min") + col("salary_max")) / 2, 
        lit(0.0)
    )
)

# 3.2. Xá»­ lÃ½ Kinh nghiá»‡m
df = df.withColumn(
    "exp_final",
    coalesce(col("exp_avg_year"), col("exp_min_year"), lit(0.0))
)

# 3.3. Táº¡o features tá»« text columns
# City features
df = df.withColumn("city_lower", lower(col("city")))
df = df.withColumn(
    "is_hcm",
    when(col("city_lower").rlike("há»“ chÃ­ minh|hcm"), 1.0).otherwise(0.0)
)
df = df.withColumn(
    "is_hanoi",
    when(col("city_lower").rlike("hÃ  ná»™i|ha noi|hanoi"), 1.0).otherwise(0.0)
)
df = df.withColumn(
    "is_danang",
    when(col("city_lower").rlike("Ä‘Ã  náºµng|da nang"), 1.0).otherwise(0.0)
)

# Job fields features
df = df.withColumn("job_fields_lower", lower(col("job_fields")))
df = df.withColumn(
    "is_it",
    when(col("job_fields_lower").rlike("it|pháº§n má»m|developer|láº­p trÃ¬nh|data|ai|software"), 1.0).otherwise(0.0)
)
df = df.withColumn(
    "is_sales",
    when(col("job_fields_lower").rlike("bÃ¡n hÃ ng|kinh doanh|sales|tiáº¿p thá»‹|marketing"), 1.0).otherwise(0.0)
)
df = df.withColumn(
    "is_finance",
    when(col("job_fields_lower").rlike("tÃ i chÃ­nh|ngÃ¢n hÃ ng|káº¿ toÃ¡n|finance|banking"), 1.0).otherwise(0.0)
)
df = df.withColumn(
    "is_education",
    when(col("job_fields_lower").rlike("giÃ¡o dá»¥c|Ä‘Ã o táº¡o|giÃ¡o viÃªn|education"), 1.0).otherwise(0.0)
)
df = df.withColumn(
    "is_engineering",
    when(col("job_fields_lower").rlike("ká»¹ thuáº­t|cÆ¡ khÃ­|Ä‘iá»‡n|xÃ¢y dá»±ng|engineer"), 1.0).otherwise(0.0)
)

# Position level features - 7 cáº¥p báº­c theo thá»‹ trÆ°á»ng lao Ä‘á»™ng VN
df = df.withColumn("pos_lower", lower(col("position_level")))

# 1. Thá»±c táº­p sinh (Intern)
df = df.withColumn(
    "is_intern",
    when(col("pos_lower").rlike("thá»±c táº­p|intern|internship"), 1.0).otherwise(0.0)
)

# 2. Fresher (Má»›i ra trÆ°á»ng, < 1 nÄƒm)
df = df.withColumn(
    "is_fresher",
    when(col("pos_lower").rlike("fresher|má»›i ra trÆ°á»ng|sinh viÃªn má»›i"), 1.0).otherwise(0.0)
)

# 3. Junior (1-2 nÄƒm kinh nghiá»‡m)
df = df.withColumn(
    "is_junior",
    when(col("pos_lower").rlike("junior"), 1.0).otherwise(0.0)
)

# 4. NhÃ¢n viÃªn/ChuyÃªn viÃªn (Staff - 2-4 nÄƒm)
df = df.withColumn(
    "is_staff",
    when(col("pos_lower").rlike("nhÃ¢n viÃªn|chuyÃªn viÃªn|staff|employee"), 1.0).otherwise(0.0)
)

# 5. Senior (4-7 nÄƒm)
df = df.withColumn(
    "is_senior",
    when(col("pos_lower").rlike("senior|chuyÃªn gia|chuyÃªn viÃªn cao cáº¥p"), 1.0).otherwise(0.0)
)

# 6. TrÆ°á»Ÿng nhÃ³m (Team Lead - 5-8 nÄƒm)
df = df.withColumn(
    "is_team_lead",
    when(col("pos_lower").rlike("trÆ°á»Ÿng nhÃ³m|team lead|leader|tech lead"), 1.0).otherwise(0.0)
)

# 7. Quáº£n lÃ½/TrÆ°á»Ÿng phÃ²ng (Manager - 7+ nÄƒm)
df = df.withColumn(
    "is_manager",
    when(col("pos_lower").rlike("trÆ°á»Ÿng phÃ²ng|quáº£n lÃ½|giÃ¡m Ä‘á»‘c|manager|head|director"), 1.0).otherwise(0.0)
)

# ====================================================
# 4. Lá»ŒC Dá»® LIá»†U Há»¢P Lá»†
# ====================================================
# Chá»‰ giá»¯ jobs cÃ³ lÆ°Æ¡ng há»£p lá»‡ (> 0 triá»‡u) vÃ  kinh nghiá»‡m há»£p lá»‡ (0-30 nÄƒm)
df = df.filter(
    (col("salary_final") > 0) &         # Bá» filter >= 5 triá»‡u Ä‘á»ƒ giá»¯ láº¡i intern
    (col("salary_final") <= 200) &
    (col("exp_final") >= 0) &
    (col("exp_final") <= 30)
)

print(f">>> Sá»‘ jobs sau khi lá»c: {df.count()}")

# ====================================================
# 5. FEATURE ENGINEERING - 16 features
# ====================================================
feature_cols = [
    "exp_final",        # Kinh nghiá»‡m (nÄƒm)
    "is_hcm",           # ThÃ nh phá»‘ HCM
    "is_hanoi",         # ThÃ nh phá»‘ HÃ  Ná»™i
    "is_danang",        # ThÃ nh phá»‘ ÄÃ  Náºµng
    "is_it",            # NgÃ nh IT
    "is_sales",         # NgÃ nh Sales
    "is_finance",       # NgÃ nh TÃ i chÃ­nh
    "is_education",     # NgÃ nh GiÃ¡o dá»¥c
    "is_engineering",   # NgÃ nh Ká»¹ thuáº­t
    "is_intern",        # Cáº¥p 1: Thá»±c táº­p sinh
    "is_fresher",       # Cáº¥p 2: Fresher
    "is_junior",        # Cáº¥p 3: Junior
    "is_staff",         # Cáº¥p 4: NhÃ¢n viÃªn/ChuyÃªn viÃªn
    "is_senior",        # Cáº¥p 5: Senior
    "is_team_lead",     # Cáº¥p 6: TrÆ°á»Ÿng nhÃ³m
    "is_manager"        # Cáº¥p 7: Quáº£n lÃ½/TrÆ°á»Ÿng phÃ²ng
]

# Fill null values vá»›i 0
for col_name in feature_cols:
    df = df.fillna({col_name: 0.0})

# ====================================================
# 6. CHIA TRAIN/TEST (80/20)
# ====================================================
print("\n>>> CHIA Dá»® LIá»†U TRAIN/TEST (80/20):")
train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)
print(f"    - Tá»•ng sá»‘ jobs: {df.count()}")
print(f"    - Train set (80%): {train_df.count()} jobs")
print(f"    - Test set (20%): {test_df.count()} jobs")

# ====================================================
# 7. ML PIPELINE
# ====================================================
print("\n>>> Äang xÃ¢y dá»±ng pipeline...")

# BÆ°á»›c 1: Gom features thÃ nh vector
assembler = VectorAssembler(
    inputCols=feature_cols,
    outputCol="features_raw"
)

# BÆ°á»›c 2: Chuáº©n hÃ³a dá»¯ liá»‡u
scaler = StandardScaler(
    inputCol="features_raw",
    outputCol="features",
    withStd=True,
    withMean=True
)

# BÆ°á»›c 3: Random Forest Regressor
rf = RandomForestRegressor(
    featuresCol="features",
    labelCol="salary_final",
    numTrees=100,           # Sá»‘ cÃ¢y trong rá»«ng
    maxDepth=10,            # Äá»™ sÃ¢u tá»‘i Ä‘a má»—i cÃ¢y
    seed=42
)

pipeline = Pipeline(stages=[assembler, scaler, rf])

# ====================================================
# 8. TRAIN MODEL
# ====================================================
print(">>> Äang train Random Forest Regressor...")
model = pipeline.fit(train_df)
print(">>> Train xong!")

# ====================================================
# 9. ÄÃNH GIÃ MODEL
# ====================================================
# Dá»± Ä‘oÃ¡n trÃªn táº­p test
predictions = model.transform(test_df)

# ÄÃ¡nh giÃ¡ báº±ng RMSE, MAE, RÂ²
evaluator_rmse = RegressionEvaluator(
    labelCol="salary_final",
    predictionCol="prediction",
    metricName="rmse"
)
rmse = evaluator_rmse.evaluate(predictions)

evaluator_mae = RegressionEvaluator(
    labelCol="salary_final",
    predictionCol="prediction",
    metricName="mae"
)
mae = evaluator_mae.evaluate(predictions)

evaluator_r2 = RegressionEvaluator(
    labelCol="salary_final",
    predictionCol="prediction",
    metricName="r2"
)
r2 = evaluator_r2.evaluate(predictions)

print("\n" + "="*50)
print("Káº¾T QUáº¢ ÄÃNH GIÃ MODEL")
print("="*50)
print(f"RMSE (Root Mean Square Error): {rmse:.2f} triá»‡u")
print(f"MAE (Mean Absolute Error):     {mae:.2f} triá»‡u")
print(f"RÂ² (Coefficient of Determination): {r2:.4f}")
print("(RÂ² cÃ ng gáº§n 1 cÃ ng tá»‘t, MAE/RMSE cÃ ng tháº¥p cÃ ng tá»‘t)")

# ====================================================
# 10. FEATURE IMPORTANCE
# ====================================================
print("\n" + "="*50)
print("FEATURE IMPORTANCE (Äá»˜ QUAN TRá»ŒNG Cá»¦A FEATURES)")
print("="*50)

rf_model = model.stages[-1]
importances = rf_model.featureImportances.toArray()

feature_importance = list(zip(feature_cols, importances))
feature_importance.sort(key=lambda x: x[1], reverse=True)

for feature, importance in feature_importance:
    bar = "â–ˆ" * int(importance * 100)
    print(f"{feature:.<20} {importance:.4f} {bar}")

# ====================================================
# 11. HIá»‚N THá»Š MáºªU Dá»° ÄOÃN
# ====================================================
print("\n" + "="*50)
print("MáºªU Dá»° ÄOÃN VS THá»°C Táº¾")
print("="*50)

predictions.select(
    "job_title",
    "city",
    "exp_final",
    col("salary_final").alias("actual_salary"),
    col("prediction").alias("predicted_salary")
).show(20, truncate=30)

# ====================================================
# 12. THá»NG KÃŠ THEO NGÃ€NH
# ====================================================
print("\n" + "="*50)
print("LÆ¯Æ NG TRUNG BÃŒNH THEO NGÃ€NH (Dá»° ÄOÃN)")
print("="*50)

# Táº¡o dataframe tá»•ng há»£p
all_predictions = model.transform(df)
industry_stats = all_predictions.groupBy("is_it", "is_sales", "is_finance", "is_education", "is_engineering").agg(
    {"prediction": "avg", "salary_final": "avg"}
)
industry_stats.show(10)

# ====================================================
# 13. LÆ¯U MODEL
# ====================================================
model_path = "/opt/spark/work-dir/models/salary_prediction_rf"
model.write().overwrite().save(model_path)
print(f"\n>>> ÄÃ£ lÆ°u model táº¡i: {model_path}")

# ====================================================
# 14. LÆ¯U Káº¾T QUáº¢ ÄÃNH GIÃ
# ====================================================
print("\n" + "="*50)
print("TÃ“M Táº®T MODEL")
print("="*50)
print(f"""
ğŸ“Š SALARY PREDICTION MODEL - RANDOM FOREST
â”œâ”€â”€ Thuáº­t toÃ¡n: Random Forest Regressor
â”œâ”€â”€ Sá»‘ cÃ¢y: 100
â”œâ”€â”€ Äá»™ sÃ¢u tá»‘i Ä‘a: 10
â”œâ”€â”€ Train/Test: 80/20
â”‚
â”œâ”€â”€ Káº¾T QUáº¢:
â”‚   â”œâ”€â”€ RMSE: {rmse:.2f} triá»‡u
â”‚   â”œâ”€â”€ MAE:  {mae:.2f} triá»‡u
â”‚   â””â”€â”€ RÂ²:   {r2:.4f}
â”‚
â””â”€â”€ TOP FEATURES:
    â”œâ”€â”€ {feature_importance[0][0]}: {feature_importance[0][1]:.4f}
    â”œâ”€â”€ {feature_importance[1][0]}: {feature_importance[1][1]:.4f}
    â””â”€â”€ {feature_importance[2][0]}: {feature_importance[2][1]:.4f}
""")

spark.stop()
print("\nâœ… HOÃ€N THÃ€NH!")
