import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go

# ====================================================
# C·∫§U H√åNH TRANG
# ====================================================
st.set_page_config(
    page_title="Job Attractiveness Analyzer",
    page_icon="üéØ",
    layout="wide"
)

# ====================================================
# K·∫æT N·ªêI CASSANDRA
# ====================================================
import os

CASSANDRA_HOST = os.getenv('CASSANDRA_HOST', 'localhost')  # Docker: cassandra, Local: localhost

@st.cache_resource
def get_cassandra_session():
    """K·∫øt n·ªëi t·ªõi Cassandra"""
    try:
        from cassandra.cluster import Cluster
        cluster = Cluster([CASSANDRA_HOST], port=9042)
        session = cluster.connect('job_analytics')
        return session
    except Exception as e:
        return None

@st.cache_data(ttl=60)
def load_data():
    """ƒê·ªçc d·ªØ li·ªáu t·ª´ Cassandra ho·∫∑c t·∫°o demo data"""
    session = get_cassandra_session()
    
    if session is not None:
        try:
            query = "SELECT * FROM job_postings"
            rows = session.execute(query)
            df = pd.DataFrame(list(rows))
            if not df.empty:
                return df, True  # True = real data
        except Exception as e:
            pass
    
    # N·∫øu kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c Cassandra, t·∫°o demo data
    import numpy as np
    np.random.seed(42)
    n = 500
    
    demo_df = pd.DataFrame({
        'job_title': [f'Job {i}' for i in range(n)],
        'city': np.random.choice(['H·ªì Ch√≠ Minh', 'H√† N·ªôi', 'ƒê√† N·∫µng', 'B√¨nh D∆∞∆°ng', 'C·∫ßn Th∆°'], n),
        'salary_avg': np.random.uniform(5, 50, n),
        'salary_min': np.random.uniform(3, 30, n),
        'salary_max': np.random.uniform(20, 60, n),
        'exp_avg_year': np.random.uniform(0, 10, n),
        'exp_min_year': np.random.uniform(0, 5, n),
        'job_fields': np.random.choice(['IT', 'Sales', 'Marketing', 'Finance', 'HR'], n),
    })
    
    return demo_df, False  # False = demo data

@st.cache_data(ttl=60)
def load_clusters():
    """ƒê·ªçc d·ªØ li·ªáu clustering t·ª´ Cassandra"""
    session = get_cassandra_session()
    
    if session is not None:
        try:
            query = "SELECT * FROM job_clusters"
            rows = session.execute(query)
            df = pd.DataFrame(list(rows))
            if not df.empty:
                return df, True
        except Exception as e:
            pass
    
    # Demo data n·∫øu kh√¥ng c√≥
    import numpy as np
    np.random.seed(42)
    n = 500
    demo_df = pd.DataFrame({
        'job_title': [f'Job {i}' for i in range(n)],
        'city': np.random.choice(['H·ªì Ch√≠ Minh', 'H√† N·ªôi', 'ƒê√† N·∫µng'], n),
        'salary_final': np.random.uniform(5, 50, n),
        'exp_final': np.random.uniform(0, 10, n),
        'job_fields': np.random.choice(['IT', 'Sales', 'Finance'], n),
        'cluster': np.random.choice([0, 1, 2, 3, 4], n),
    })
    return demo_df, False

@st.cache_data(ttl=60)
def load_skill_scores():
    """ƒê·ªçc d·ªØ li·ªáu skill hot scores t·ª´ Cassandra"""
    session = get_cassandra_session()
    
    if session is not None:
        try:
            query = "SELECT * FROM skill_hot_scores"
            rows = session.execute(query)
            df = pd.DataFrame(list(rows))
            if not df.empty:
                return df, True
        except Exception as e:
            pass
    
    # Demo data n·∫øu kh√¥ng c√≥
    import numpy as np
    np.random.seed(42)
    skills = ['Python', 'Java', 'JavaScript', 'SQL', 'React', 'AWS', 'Docker', 'Excel', 'C++', 'Node.js',
              'Angular', 'PHP', 'Machine Learning', 'Data Analysis', 'Project Management']
    n = len(skills)
    demo_df = pd.DataFrame({
        'skill': skills,
        'job_count': np.random.randint(50, 5000, n),
        'avg_salary': np.random.uniform(10, 40, n),
        'avg_exp': np.random.uniform(0.5, 5, n),
        'big_city_ratio': np.random.uniform(0.3, 0.9, n),
        'skill_hot_score': np.random.uniform(0.2, 0.9, n),
        'predicted_hot_score': np.random.uniform(0.2, 0.9, n),
    })
    return demo_df, False

# ====================================================
# H√ÄM D·ª∞ ƒêO√ÅN
# ====================================================
def predict_job_attractiveness(salary, experience):
    """
    D·ª± ƒëo√°n job c√≥ h·∫•p d·∫´n kh√¥ng d·ª±a tr√™n logic ƒë√£ ƒë·ªãnh nghƒ©a:
    - Hot: L∆∞∆°ng >= 15tr V√Ä KN <= 2 nƒÉm
    - Hot: L∆∞∆°ng >= 30tr
    """
    if salary >= 15 and experience <= 2:
        return True, "L∆∞∆°ng t·ªët cho ng∆∞·ªùi √≠t kinh nghi·ªám"
    elif salary >= 30:
        return True, "L∆∞∆°ng cao, ai c≈©ng mu·ªën"
    else:
        return False, "Ch∆∞a ƒë·ªß ƒëi·ªÅu ki·ªán h·∫•p d·∫´n"

# ====================================================
# GIAO DI·ªÜN CH√çNH
# ====================================================
# st.title("üéØ Job Attractiveness Analyzer")
st.markdown("**Ph√¢n t√≠ch xu h∆∞·ªõng vi·ªác l√†m v√† d·ª± ƒëo√°n m·ª©c ƒë·ªô h·∫•p d·∫´n c·ªßa c√°c k·ªπ nƒÉng tr√™n th·ªã tr∆∞·ªùng lao ƒë·ªông**")

st.divider()

# Load d·ªØ li·ªáu
df, is_real_data = load_data()

if not is_real_data:
    st.warning("‚ö†Ô∏è ƒêang s·ª≠ d·ª•ng **demo data** v√¨ kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c Cassandra. H√£y ch·∫°y Docker containers tr∆∞·ªõc!")

# T·∫°o c√°c c·ªôt t√≠nh to√°n n·∫øu ch∆∞a c√≥
if len(df) > 0:
    if 'salary_final' not in df.columns:
        df['salary_final'] = df['salary_avg'].fillna(
            (df['salary_min'].fillna(0) + df['salary_max'].fillna(0)) / 2
        ).fillna(0)
    if 'exp_final' not in df.columns:
        df['exp_final'] = df['exp_avg_year'].fillna(df['exp_min_year'].fillna(0))

# ====================================================
# TAB LAYOUT
# ====================================================
tab1, tab4, tab5, tab7 = st.tabs([
    "üìä Th·ªëng k√™", "üéØ Ph√¢n c·ª•m Job", 
    "üî• Skill Hot", "üîÆ D·ª± ƒëo√°n L∆∞∆°ng"
])

# ====================================================
# TAB 1: TH·ªêNG K√ä T·ªîNG QUAN
# ====================================================
with tab1:
    st.header("üìä Th·ªëng k√™ t·ªïng quan")
    
    if len(df) == 0:
        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu. H√£y ch·∫°y ETL pipeline tr∆∞·ªõc!")
    else:
        # T√≠nh to√°n th·ªëng k√™ c∆° b·∫£n
        total_jobs = len(df)
        
        # Hi·ªÉn th·ªã t·ªïng s·ªë jobs
        st.metric(
            label="üìã T·ªïng s·ªë Job trong h·ªá th·ªëng",
            value=f"{total_jobs:,} jobs"
        )
        
        st.divider()
        
        # Th·ªëng k√™ theo th√†nh ph·ªë
        st.subheader("üìç Ph√¢n b·ªë theo Th√†nh ph·ªë")
        city_counts = df['city'].value_counts().head(10)
        fig_city = px.bar(
            x=city_counts.index, 
            y=city_counts.values,
            labels={'x': 'Th√†nh ph·ªë', 'y': 'S·ªë l∆∞·ª£ng Job'},
            color=city_counts.values,
            color_continuous_scale='Blues'
        )
        st.plotly_chart(fig_city, use_container_width=True)





# ====================================================
# FOOTER
# ====================================================
st.divider()
st.markdown("""
<div style='text-align: center; color: gray;'>
    üéì ƒê·ªì √°n Big Data - Job Attractiveness Analysis<br>
    Built with Streamlit, Spark, Cassandra, Kafka
</div>
""", unsafe_allow_html=True)

# ====================================================
# TAB 4: CLUSTERING
# ====================================================
with tab4:
    # st.header("üéØ K·∫øt qu·∫£ K-Means Clustering")
    
    df_clusters, is_real_clusters = load_clusters()
    
    if not is_real_clusters:
        st.warning("‚ö†Ô∏è ƒêang d√πng demo data. H√£y ch·∫°y `train_kmeans.py` ƒë·ªÉ c√≥ k·∫øt qu·∫£ th·ª±c!")
    
    if len(df_clusters) == 0:
        st.error("Kh√¥ng c√≥ d·ªØ li·ªáu clustering!")
    else:
        # S·ª≠ d·ª•ng t√™n nh√≥m m·∫∑c ƒë·ªãnh (Nh√≥m 0, Nh√≥m 1...) ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh ch√≠nh x√°c
        # v√¨ m·ªói l·∫ßn train l·∫°i model, th·ª© t·ª± c√°c cluster c√≥ th·ªÉ thay ƒë·ªïi
        df_clusters['cluster_name'] = df_clusters['cluster'].apply(lambda x: f"Nh√≥m {x}")
        
        # Th·ªëng k√™ s·ªë jobs m·ªói cluster
        st.subheader("üìä Ph√¢n b·ªë Jobs theo Nh√≥m")
        cluster_counts = df_clusters['cluster'].value_counts().sort_index()
        cluster_names_list = [f"Nh√≥m {i}" for i in cluster_counts.index]
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Bi·ªÉu ƒë·ªì c·ªôt
            fig_bar = px.bar(
                x=cluster_names_list,
                y=cluster_counts.values,
                labels={'x': 'Nh√≥m c√¥ng vi·ªác', 'y': 'S·ªë l∆∞·ª£ng Jobs'},
                color=cluster_names_list,
                color_discrete_sequence=px.colors.qualitative.Set2
            )
            fig_bar.update_layout(showlegend=False)
            st.plotly_chart(fig_bar, use_container_width=True)
        
        with col2:
            # Bi·ªÉu ƒë·ªì tr√≤n
            fig_pie = px.pie(
                names=cluster_names_list,
                values=cluster_counts.values,
                color_discrete_sequence=px.colors.qualitative.Set2
            )
            st.plotly_chart(fig_pie, use_container_width=True)
        
        # ƒê·∫∑c ƒëi·ªÉm t·ª´ng cluster
        st.subheader("üìã ƒê·∫∑c ƒëi·ªÉm trung b√¨nh t·ª´ng Nh√≥m")
        cluster_stats = df_clusters.groupby('cluster').agg({
            'salary_final': 'mean',
            'exp_final': 'mean'
        }).round(2)
        cluster_stats['T√™n nh√≥m'] = [f"Nh√≥m {i}" for i in cluster_stats.index]
        cluster_stats.columns = ['L∆∞∆°ng TB (tri·ªáu)', 'KN TB (nƒÉm)', 'T√™n nh√≥m']
        cluster_stats['S·ªë Jobs'] = cluster_counts.values
        cluster_stats = cluster_stats[['T√™n nh√≥m', 'L∆∞∆°ng TB (tri·ªáu)', 'KN TB (nƒÉm)', 'S·ªë Jobs']]
        st.dataframe(cluster_stats, use_container_width=True)
        
        # Scatter plot
        st.subheader("üîç Ph√¢n b·ªë L∆∞∆°ng vs Kinh nghi·ªám theo Nh√≥m")
        fig_scatter = px.scatter(
            df_clusters,
            x='salary_final',
            y='exp_final',
            color='cluster_name',
            labels={'salary_final': 'L∆∞∆°ng (tri·ªáu)', 'exp_final': 'Kinh nghi·ªám (nƒÉm)', 'cluster_name': 'Nh√≥m'},
            color_discrete_sequence=px.colors.qualitative.Set2,
            opacity=0.6
        )
        st.plotly_chart(fig_scatter, use_container_width=True)
        
        # Top jobs m·ªói cluster
        st.subheader("üìù M·∫´u Jobs trong m·ªói Nh√≥m")
        
        # Dropdown v·ªõi t√™n ti·∫øng Vi·ªát
        col1, col2 = st.columns([2, 1])
        
        with col1:
            cluster_options = {f"Nh√≥m {c}": c for c in sorted(df_clusters['cluster'].unique())}
            selected_name = st.selectbox("Ch·ªçn Nh√≥m:", list(cluster_options.keys()))
            selected_cluster = cluster_options[selected_name]
        
        with col2:
            show_all = st.checkbox("Xem t·∫•t c·∫£", value=False)
            if not show_all:
                num_rows = st.slider("S·ªë jobs hi·ªÉn th·ªã:", min_value=10, max_value=1000, value=50, step=10)
            else:
                num_rows = len(cluster_data)
        
        # L·ªçc data theo cluster
        cluster_data = df_clusters[df_clusters['cluster'] == selected_cluster]
        
        # Hi·ªÉn th·ªã th√¥ng tin t·ªïng quan
        showing_text = "t·∫•t c·∫£" if show_all else f"{min(num_rows, len(cluster_data)):,}"
        st.info(f"üìä ƒêang hi·ªÉn th·ªã **{showing_text}** / **{len(cluster_data):,}** jobs trong nh√≥m **{selected_name}**")
        
        # Hi·ªÉn th·ªã b·∫£ng v·ªõi s·ªë l∆∞·ª£ng ƒë√£ ch·ªçn
        st.dataframe(
            cluster_data[['job_title', 'city', 'salary_final', 'exp_final', 'job_fields']].head(num_rows).rename(columns={
                'job_title': 'T√™n c√¥ng vi·ªác',
                'city': 'Th√†nh ph·ªë',
                'salary_final': 'L∆∞∆°ng (tri·ªáu)',
                'exp_final': 'Kinh nghi·ªám (nƒÉm)',
                'job_fields': 'Lƒ©nh v·ª±c'
            }),
            use_container_width=True,
            height=400
        )

# ====================================================
# TAB 5: SKILL HOT SCORE
# ====================================================
with tab5:
    st.header("üî• Ph√¢n t√≠ch ƒë·ªô h·∫•p d·∫´n c·ªßa K·ªπ nƒÉng")
    
    df_skills, is_real_skills = load_skill_scores()
    
    if not is_real_skills:
        st.warning("‚ö†Ô∏è ƒêang d√πng demo data. H√£y ch·∫°y `train_gbt_cassandra.py` ƒë·ªÉ c√≥ k·∫øt qu·∫£ th·ª±c!")
    
    if len(df_skills) == 0:
        st.error("Kh√¥ng c√≥ d·ªØ li·ªáu skill!")
    else:
        # S·∫Øp x·∫øp theo hot score
        df_skills = df_skills.sort_values('predicted_hot_score', ascending=False)
        
        # Th·ªëng k√™ t·ªïng quan
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("üìä T·ªïng s·ªë k·ªπ nƒÉng", f"{len(df_skills):,}")
        with col2:
            st.metric("üî• Hot Score cao nh·∫•t", f"{df_skills['predicted_hot_score'].max():.2f}")
        with col3:
            top_skill = df_skills.iloc[0]['skill'] if len(df_skills) > 0 else "N/A"
            st.metric("üèÜ K·ªπ nƒÉng hot nh·∫•t", top_skill)
        
        st.divider()
        
        # Top k·ªπ nƒÉng h·∫•p d·∫´n nh·∫•t
        st.subheader("üèÜ Top 20 K·ªπ nƒÉng h·∫•p d·∫´n nh·∫•t")
        
        top_n = st.slider("S·ªë k·ªπ nƒÉng hi·ªÉn th·ªã:", min_value=10, max_value=50, value=20)
        top_skills = df_skills.head(top_n)
        
        # Bar chart
        fig_bar = px.bar(
            top_skills,
            x='skill',
            y='predicted_hot_score',
            color='predicted_hot_score',
            color_continuous_scale='Reds',
            labels={'skill': 'K·ªπ nƒÉng', 'predicted_hot_score': 'Hot Score'},
            title=f'Top {top_n} K·ªπ nƒÉng Hot nh·∫•t'
        )
        fig_bar.update_layout(xaxis_tickangle=-45, showlegend=False)
        st.plotly_chart(fig_bar, use_container_width=True)
        
        # Chi ti·∫øt t·ª´ng k·ªπ nƒÉng
        st.subheader("üìã Chi ti·∫øt K·ªπ nƒÉng")
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            # B·∫£ng th·ªëng k√™
            display_df = df_skills[['skill', 'predicted_hot_score', 'job_count', 'avg_salary', 'avg_exp']].copy()
            display_df.columns = ['K·ªπ nƒÉng', 'Hot Score', 'S·ªë Jobs', 'L∆∞∆°ng TB', 'KN TB']
            display_df['Hot Score'] = display_df['Hot Score'].round(3)
            display_df['L∆∞∆°ng TB'] = display_df['L∆∞∆°ng TB'].round(1)
            display_df['KN TB'] = display_df['KN TB'].round(1)
            st.dataframe(display_df, use_container_width=True, height=400)
        
        with col2:
            # Scatter plot: L∆∞∆°ng vs S·ªë jobs, m√†u = Hot score
            fig_scatter = px.scatter(
                df_skills,
                x='avg_salary',
                y='job_count',
                size='predicted_hot_score',
                color='predicted_hot_score',
                hover_name='skill',
                color_continuous_scale='Reds',
                labels={
                    'avg_salary': 'L∆∞∆°ng trung b√¨nh (tri·ªáu)',
                    'job_count': 'S·ªë l∆∞·ª£ng Jobs',
                    'predicted_hot_score': 'Hot Score'
                },
                title='Ph√¢n b·ªë k·ªπ nƒÉng theo L∆∞∆°ng v√† Nhu c·∫ßu'
            )
            st.plotly_chart(fig_scatter, use_container_width=True)
        
        # So s√°nh k·ªπ nƒÉng
        st.subheader("‚öñÔ∏è So s√°nh K·ªπ nƒÉng")
        
        available_skills = df_skills['skill'].tolist()
        selected_skills = st.multiselect(
            "Ch·ªçn k·ªπ nƒÉng ƒë·ªÉ so s√°nh:",
            available_skills,
            default=available_skills[:5] if len(available_skills) >= 5 else available_skills
        )
        
        if selected_skills:
            compare_df = df_skills[df_skills['skill'].isin(selected_skills)]
            
            # Radar chart
            fig_radar = go.Figure()
            
            for _, row in compare_df.iterrows():
                fig_radar.add_trace(go.Scatterpolar(
                    r=[row['predicted_hot_score']*100, row['avg_salary'], row['job_count']/100, (1-row['avg_exp']/10)*10, row['big_city_ratio']*100],
                    theta=['Hot Score', 'L∆∞∆°ng TB', 'Nhu c·∫ßu', 'D·ªÖ v√†o ngh·ªÅ', 'TP L·ªõn'],
                    fill='toself',
                    name=row['skill']
                ))
            
            fig_radar.update_layout(
                polar=dict(radialaxis=dict(visible=True)),
                showlegend=True,
                title="So s√°nh c√°c k·ªπ nƒÉng"
            )
            st.plotly_chart(fig_radar, use_container_width=True)



# ====================================================
# TAB 7: SALARY PREDICTION (Using pre-trained model)
# ====================================================
with tab7:
    st.header("üîÆ D·ª± ƒëo√°n L∆∞∆°ng")
    # st.markdown("**D·ª± ƒëo√°n m·ª©c l∆∞∆°ng d·ª±a tr√™n Random Forest model ƒë√£ train**")
    
    st.divider()
    st.markdown("Nh·∫≠p th√¥ng tin c√¥ng vi·ªác ƒë·ªÉ d·ª± ƒëo√°n m·ª©c l∆∞∆°ng ")
    
    # Session state for loaded model
    if 'salary_model_loaded' not in st.session_state:
        st.session_state.salary_model_loaded = None
    
    # Experience range mapping by position level
    EXP_RANGES = {
        "üéì Th·ª±c t·∫≠p sinh": (0, 0, 0),          # min, max, default
        "üå± Fresher": (0, 1, 0),
        "üìö Junior": (1, 2, 1),
        "üë§ Nh√¢n vi√™n/Chuy√™n vi√™n": (2, 4, 3),
        "‚≠ê Senior": (4, 7, 5),
        "üë• Tr∆∞·ªüng nh√≥m": (5, 10, 6),
        "üëî Qu·∫£n l√Ω/Tr∆∞·ªüng ph√≤ng": (7, 20, 10),
    }
    
    # Initialize session state for position
    if 'selected_position' not in st.session_state:
        st.session_state.selected_position = "üéì Th·ª±c t·∫≠p sinh"
    
    st.markdown("##### üìç Th√¥ng tin v·ªã tr√≠")
    pred_col1, pred_col2 = st.columns(2)
    
    with pred_col2:
        pred_position = st.selectbox("C·∫•p b·∫≠c", 
            list(EXP_RANGES.keys()),
            key="pred_position")
        st.session_state.selected_position = pred_position
    
    # Get experience range based on selected position
    exp_min, exp_max, exp_default = EXP_RANGES[pred_position]
    
    with pred_col1:
        pred_city = st.selectbox("Th√†nh ph·ªë", 
            ["H·ªì Ch√≠ Minh", "H√† N·ªôi", "ƒê√† N·∫µng", "Kh√°c"],
            key="pred_city")
        
        # Dynamic slider based on position
        if exp_min == exp_max:
            # Fixed value (e.g., Intern = 0)
            pred_experience = exp_min
            st.info(f"‚è±Ô∏è Kinh nghi·ªám: **{exp_min} nƒÉm** (c·ªë ƒë·ªãnh cho {pred_position})")
        else:
            pred_experience = st.slider(
                f"S·ªë nƒÉm kinh nghi·ªám ({exp_min}-{exp_max} nƒÉm)", 
                exp_min, exp_max, exp_default, 
                key=f"pred_exp_{pred_position}"  # Unique key per position
            )
    
    st.markdown("##### üíº Lƒ©nh v·ª±c c√¥ng vi·ªác")
    field_col1, field_col2, field_col3 = st.columns(3)
    
    with field_col1:
        is_it = st.checkbox("üñ•Ô∏è IT/Ph·∫ßn m·ªÅm", key="is_it")
        is_finance = st.checkbox("üí∞ T√†i ch√≠nh/Ng√¢n h√†ng", key="is_finance")
    with field_col2:
        is_sales = st.checkbox("üìà Sales/Marketing", key="is_sales")
        is_education = st.checkbox("üìö Gi√°o d·ª•c", key="is_education")
    with field_col3:
        is_engineering = st.checkbox("üîß K·ªπ thu·∫≠t/Engineering", key="is_engineering")
    
    predict_submitted = st.button("üîÆ D·ª± ƒëo√°n L∆∞∆°ng", type="primary")
    
    if predict_submitted:
        try:
            from pyspark.sql import SparkSession
            from pyspark.ml import PipelineModel
            from pyspark.sql.types import StructType, StructField, DoubleType
            
            with st.spinner("ƒêang load model v√† d·ª± ƒëo√°n..."):
                # Convert inputs to features
                is_hcm = 1.0 if "H·ªì Ch√≠ Minh" in pred_city else 0.0
                is_hanoi = 1.0 if "H√† N·ªôi" in pred_city else 0.0
                is_danang = 1.0 if "ƒê√† N·∫µng" in pred_city else 0.0
                
                # Position features - 7 levels (mutually exclusive)
                is_intern = 1.0 if "Th·ª±c t·∫≠p" in pred_position else 0.0
                is_fresher = 1.0 if "Fresher" in pred_position else 0.0
                is_junior = 1.0 if "Junior" in pred_position else 0.0
                is_staff = 1.0 if "Nh√¢n vi√™n" in pred_position else 0.0
                is_senior = 1.0 if "Senior" in pred_position else 0.0
                is_team_lead = 1.0 if "Tr∆∞·ªüng nh√≥m" in pred_position else 0.0
                is_manager = 1.0 if "Qu·∫£n l√Ω" in pred_position else 0.0
                
                exp_final = float(pred_experience)
                
                # Create Spark session
                spark = SparkSession.builder \
                    .appName("SalaryPrediction_UI") \
                    .config("spark.driver.memory", "1g") \
                    .getOrCreate()
                
                # Load model
                model_path = "/opt/spark/work-dir/models/salary_prediction_rf"
                
                try:
                    model = PipelineModel.load(model_path)
                    st.session_state.salary_model_loaded = model
                except Exception as e:
                    # Try alternative paths
                    import os
                    alt_paths = [
                        "./models/salary_prediction_rf",
                        os.path.join(os.path.dirname(__file__), "models", "salary_prediction_rf")
                    ]
                    model = None
                    for path in alt_paths:
                        if os.path.exists(path):
                            try:
                                model = PipelineModel.load(path)
                                break
                            except:
                                continue
                    
                    if model is None:
                        st.error(f"‚ùå Kh√¥ng th·ªÉ load model! Vui l√≤ng ch·∫°y train_salary_prediction.py tr∆∞·ªõc.")
                        spark.stop()
                        st.stop()
                
                # Create input DataFrame with 16 features
                schema = StructType([
                    StructField("exp_final", DoubleType(), True),
                    StructField("is_hcm", DoubleType(), True),
                    StructField("is_hanoi", DoubleType(), True),
                    StructField("is_danang", DoubleType(), True),
                    StructField("is_it", DoubleType(), True),
                    StructField("is_sales", DoubleType(), True),
                    StructField("is_finance", DoubleType(), True),
                    StructField("is_education", DoubleType(), True),
                    StructField("is_engineering", DoubleType(), True),
                    StructField("is_intern", DoubleType(), True),
                    StructField("is_fresher", DoubleType(), True),
                    StructField("is_junior", DoubleType(), True),
                    StructField("is_staff", DoubleType(), True),
                    StructField("is_senior", DoubleType(), True),
                    StructField("is_team_lead", DoubleType(), True),
                    StructField("is_manager", DoubleType(), True),
                ])
                
                input_data = [(
                    exp_final,
                    is_hcm,
                    is_hanoi,
                    is_danang,
                    1.0 if is_it else 0.0,
                    1.0 if is_sales else 0.0,
                    1.0 if is_finance else 0.0,
                    1.0 if is_education else 0.0,
                    1.0 if is_engineering else 0.0,
                    is_intern,
                    is_fresher,
                    is_junior,
                    is_staff,
                    is_senior,
                    is_team_lead,
                    is_manager,
                )]
                
                input_df = spark.createDataFrame(input_data, schema)
                
                # Make prediction
                prediction_df = model.transform(input_df)
                raw_salary = prediction_df.select("prediction").collect()[0][0]
                
                # ƒêi·ªÅu ch·ªânh l∆∞∆°ng theo c·∫•p b·∫≠c (do data thi·∫øu c√¢n b·∫±ng)
                # H·ªá s·ªë ƒëi·ªÅu ch·ªânh d·ª±a tr√™n m·ª©c l∆∞∆°ng th·ª±c t·∫ø th·ªã tr∆∞·ªùng VN
                SALARY_ADJUSTMENT = {
                    "üéì Th·ª±c t·∫≠p sinh": (2.0, 5.0),     # Floor, Ceiling (tri·ªáu)
                    "üå± Fresher": (4.0, 10.0),
                    "üìö Junior": (7.0, 15.0),
                    "üë§ Nh√¢n vi√™n/Chuy√™n vi√™n": (10.0, 25.0),
                    "‚≠ê Senior": (18.0, 45.0),
                    "üë• Tr∆∞·ªüng nh√≥m": (25.0, 60.0),
                    "üëî Qu·∫£n l√Ω/Tr∆∞·ªüng ph√≤ng": (35.0, 100.0),
                }
                
                floor_salary, ceiling_salary = SALARY_ADJUSTMENT.get(pred_position, (5.0, 100.0))
                
                # Clamp predicted salary within reasonable range for position
                predicted_salary = max(floor_salary, min(raw_salary, ceiling_salary))
                
                # Bonus for IT field
                if is_it and predicted_salary < ceiling_salary:
                    predicted_salary = min(predicted_salary * 1.2, ceiling_salary)
                
                # Display result
                st.success(f"üí∞ **L∆∞∆°ng d·ª± ƒëo√°n: {predicted_salary:.1f} Tri·ªáu VND/th√°ng**")
                
                # Debug info
                with st.expander("üìä Chi ti·∫øt t√≠nh to√°n"):
                    st.write(f"- Model raw prediction: **{raw_salary:.1f}** tri·ªáu")
                    st.write(f"- ƒêi·ªÅu ch·ªânh theo c·∫•p b·∫≠c: **{floor_salary}-{ceiling_salary}** tri·ªáu")
                    st.write(f"- K·∫øt qu·∫£ sau ƒëi·ªÅu ch·ªânh: **{predicted_salary:.1f}** tri·ªáu")
                
                # Feature summary
                features_selected = []
                if is_hcm: features_selected.append("üìç HCM")
                if is_hanoi: features_selected.append("üìç H√† N·ªôi")
                if is_danang: features_selected.append("üìç ƒê√† N·∫µng")
                if is_it: features_selected.append("üñ•Ô∏è IT")
                if is_sales: features_selected.append("üìà Sales")
                if is_finance: features_selected.append("üí∞ T√†i ch√≠nh")
                if is_education: features_selected.append("üìö Gi√°o d·ª•c")
                if is_engineering: features_selected.append("üîß K·ªπ thu·∫≠t")
                
                st.info(f"""
                **Th√¥ng tin ƒë·∫ßu v√†o:**
                - ‚è±Ô∏è Kinh nghi·ªám: **{pred_experience} nƒÉm**
                - üìä C·∫•p b·∫≠c: **{pred_position}**
                - üè∑Ô∏è Lƒ©nh v·ª±c: {', '.join(features_selected) if features_selected else 'Kh√¥ng x√°c ƒë·ªãnh'}
                """)
                
                spark.stop()
                
        except Exception as e:
            st.error(f"L·ªói d·ª± ƒëo√°n: {str(e)}")
            import traceback
            with st.expander("Chi ti·∫øt l·ªói"):
                st.code(traceback.format_exc())

